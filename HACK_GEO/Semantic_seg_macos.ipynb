{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ! pip install -q segmentation-models-pytorch\n",
    "\n",
    "# ! pip install -q segmentation-models-pytorch\n",
    "# ! pip install -q torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" )\n",
    "# torch.set_default_tensor_type(torch.IntTensor)\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souayb/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/_tensor_str.py:115: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1677744624671/work/aten/src/ATen/native/mps/operations/Indexing.mm:218.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_PATH  = 'archive/dataset/semantic_drone_dataset/label_images_semantic/'\n",
    "IMAGE_PATH = 'archive/dataset/semantic_drone_dataset/original_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images:  400\n"
     ]
    }
   ],
   "source": [
    "n_classes = 23 \n",
    "\n",
    "def create_df():\n",
    "    name = []\n",
    "    for dirname, _, filenames in os.walk(IMAGE_PATH):\n",
    "        for filename in filenames:\n",
    "            name.append(filename.split('.')[0])\n",
    "    \n",
    "    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n",
    "\n",
    "df = create_df()\n",
    "print('Total Images: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id\n",
       "0  162\n",
       "1  176\n",
       "2  348\n",
       "3  406\n",
       "4  412"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size   :  306\n",
      "Val Size     :  54\n",
      "Test Size    :  40\n"
     ]
    }
   ],
   "source": [
    "#split data\n",
    "X_trainval, X_test = train_test_split(df['id'].values, test_size=0.1, random_state=19)\n",
    "X_train, X_val = train_test_split(X_trainval, test_size=0.15, random_state=19)\n",
    "\n",
    "print('Train Size   : ', len(X_train))\n",
    "print('Val Size     : ', len(X_val))\n",
    "print('Test Size    : ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(IMAGE_PATH + df['id'][23] + '.jpg')\n",
    "img = cv2.imread(IMAGE_PATH + df['id'][23] + '.jpg')\n",
    "mask = Image.open(MASK_PATH + df['id'][23] + '.png')\n",
    "print('Image Size', np.asarray(img).shape)\n",
    "print('Mask Size', np.asarray(mask).shape)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.imshow(mask, alpha=0.6)\n",
    "plt.title('Picture with Mask Appplied')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DroneDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path, mask_path, X, mean, std, transform=None, patch=False):\n",
    "        self.img_path = img_path\n",
    "        self.mask_path = mask_path\n",
    "        self.X = X\n",
    "        self.transform = transform\n",
    "        self.patches = patch\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.img_path + self.X[idx] + '.jpg')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.mask_path + self.X[idx] + '.png', cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "\n",
    "\n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=img, mask=mask)\n",
    "            img = Image.fromarray(aug['image'])\n",
    "            mask = aug['mask']\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "        if self.transform is None:\n",
    "            img = Image.fromarray(img)\n",
    "        \n",
    "        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n",
    "        img = t(img)\n",
    "        \n",
    "        mask = torch.from_numpy(mask).long()\n",
    "\n",
    "        \n",
    "        if self.patches:\n",
    "            img, mask = self.tiles(img, mask)\n",
    "        return img, mask\n",
    "    \n",
    "  \n",
    "    def tiles(self, img, mask):\n",
    "\n",
    "        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768)\n",
    "\n",
    "        img_patches  = img_patches.contiguous().view(3,-1, 512, 768)\n",
    "\n",
    "        img_patches = img_patches.permute(1,0,2,3)\n",
    "\n",
    "        \n",
    "        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n",
    "        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n",
    "        \n",
    "        return img_patches, mask_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "t_train = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(), \n",
    "                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0,0.5),(0,0.5)),\n",
    "                     A.GaussNoise()])\n",
    "\n",
    "t_val = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),\n",
    "                   A.GridDistortion(p=0.2)])\n",
    "\n",
    "#datasets\n",
    "train_set = DroneDataset(IMAGE_PATH, MASK_PATH, X_train, mean, std, t_train, patch=False)\n",
    "val_set = DroneDataset(IMAGE_PATH, MASK_PATH, X_val, mean, std, t_val, patch=False)\n",
    "\n",
    "#dataloader\n",
    "batch_size= 2\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet('mobilenet_v2', encoder_weights='imagenet', classes=23, \\\n",
    "                 activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): MobileNetV2Encoder(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1376, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(288, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(80, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(output, mask):\n",
    "    with torch.no_grad():\n",
    "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "        correct = torch.eq(output, mask).int()\n",
    "        accuracy = float(correct.sum()) / float(correct.numel())\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=23):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False, model_type: str = 'Unet'):\n",
    "    # torch.cuda.empty_cache()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    val_iou = []; val_acc = []\n",
    "    train_iou = []; train_acc = []\n",
    "    lrs = []\n",
    "    min_loss = np.inf\n",
    "    decrease = 1 ; not_improve=0\n",
    "\n",
    "    model\n",
    "    fit_time = time.time()\n",
    "    for e in range(epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0\n",
    "        iou_score = 0\n",
    "        accuracy = 0\n",
    "        #training loop\n",
    "        model.train()\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            #training phase\n",
    "            image_tiles, mask_tiles = data\n",
    "            \n",
    "            if patch:\n",
    "                bs, n_tiles, c, h, w = image_tiles.size()\n",
    "\n",
    "                image_tiles = image_tiles.view(-1,c, h, w)\n",
    "                mask_tiles = mask_tiles.view(-1, h, w)\n",
    "            \n",
    "            image = image_tiles; mask = mask_tiles\n",
    "            #forward\n",
    "            output = model(image)\n",
    "            loss = criterion(output, mask)\n",
    "            #evaluation metrics\n",
    "            iou_score += mIoU(output, mask)\n",
    "            accuracy += pixel_accuracy(output, mask)\n",
    "            #backward\n",
    "            loss.backward()\n",
    "            optimizer.step() #update weight          \n",
    "            optimizer.zero_grad() #reset gradient\n",
    "            \n",
    "            #step the learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            scheduler.step() \n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        else:\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            test_accuracy = 0\n",
    "            val_iou_score = 0\n",
    "            #validation loop\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(tqdm(val_loader)):\n",
    "                    #reshape to 9 patches from single image, delete batch size\n",
    "                    image_tiles, mask_tiles = data\n",
    "\n",
    "                    if patch:\n",
    "                        bs, n_tiles, c, h, w = image_tiles.size()\n",
    "\n",
    "                        image_tiles = image_tiles.view(-1,c, h, w)\n",
    "                        mask_tiles = mask_tiles.view(-1, h, w)\n",
    "                    \n",
    "                    image = image_tiles; \n",
    "                    mask = mask_tiles\n",
    "                    output = model(image)\n",
    "                    #evaluation metrics\n",
    "                    val_iou_score +=  mIoU(output, mask)\n",
    "                    test_accuracy += pixel_accuracy(output, mask)\n",
    "                    #loss\n",
    "                    loss = criterion(output, mask)                                  \n",
    "                    test_loss += loss.item()\n",
    "            \n",
    "            #calculatio mean for each batch\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(val_loader))\n",
    "\n",
    "\n",
    "            if min_loss > (test_loss/len(val_loader)):\n",
    "                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n",
    "                min_loss = (test_loss/len(val_loader))\n",
    "                decrease += 1\n",
    "                if decrease % 5 == 0:\n",
    "                    print('saving model...')\n",
    "                    torch.save({\n",
    "                                'epoch': e,\n",
    "                                'model_state_dict': model.state_dict(),\n",
    "                                'loss': min_loss,\n",
    "                                },'/content/drive/MyDrive/Hack23/costum_models/'+model_type+'-{:.3f}.pt'.format(val_iou_score/len(val_loader)))\n",
    "                                        \n",
    "\n",
    "            if (test_loss/len(val_loader)) > min_loss:\n",
    "                not_improve += 1\n",
    "                min_loss = (test_loss/len(val_loader))\n",
    "                print(f'Loss Not Decrease for {not_improve} time')\n",
    "                if not_improve == 7:\n",
    "                    print('Loss not decrease for 7 times, Stop Training')\n",
    "                    break\n",
    "            \n",
    "            #iou\n",
    "            val_iou.append(val_iou_score/len(val_loader))\n",
    "            train_iou.append(iou_score/len(train_loader))\n",
    "            train_acc.append(accuracy/len(train_loader))\n",
    "            val_acc.append(test_accuracy/ len(val_loader))\n",
    "            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n",
    "                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n",
    "                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n",
    "                  \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n",
    "                  \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n",
    "                  \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n",
    "                  \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n",
    "                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
    "        \n",
    "    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n",
    "               'train_miou' :train_iou, 'val_miou':val_iou,\n",
    "               'train_acc' :train_acc, 'val_acc':val_acc,\n",
    "               'lrs': lrs}\n",
    "    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "#ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation\n",
    "#Paper-Link:  https://arxiv.org/pdf/1606.02147.pdf\n",
    "##################################################################################\n",
    "\n",
    "# @misc{Efficient-Segmentation-Networks,\n",
    "#   author = {Yu Wang},\n",
    "#   title = {Efficient-Segmentation-Networks Pytorch Implementation},\n",
    "#   year = {2019},\n",
    "#   publisher = {GitHub},\n",
    "#   journal = {GitHub repository},\n",
    "#   howpublished = {\\url{https://github.com/xiaoyufenfei/Efficient-Segmentation-Networks}},\n",
    "#   commit = {master}\n",
    "# }\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "__all__ = [\"ENet\"]\n",
    "\n",
    "\n",
    "class InitialBlock(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels, kernel_size, padding=0, bias=False,relu=True):\n",
    "        super(InitialBlock, self).__init__()\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "\n",
    "        self.main_branch = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels-3,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=2,\n",
    "            padding=padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "        # MP need padding too\n",
    "        self.ext_branch = nn.MaxPool2d(kernel_size, stride=2, padding=padding)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.out_prelu = activation\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        main = self.main_branch(input)\n",
    "        ext = self.ext_branch(input)\n",
    "\n",
    "        out = torch.cat((main, ext), dim=1)\n",
    "\n",
    "        out = self.batch_norm(out)\n",
    "        return self.out_prelu(out)\n",
    "\n",
    "class RegularBottleneck(nn.Module):\n",
    "    def __init__(self, channels, internal_ratio=4, kernel_size=3, padding=0,\n",
    "                 dilation=1, asymmetric=False, dropout_prob=0., bias=False, relu=True):\n",
    "        super(RegularBottleneck, self).__init__()\n",
    "\n",
    "        internal_channels = channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "\n",
    "        # 1x1 projection conv\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(channels, internal_channels, kernel_size=1, stride=1, bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels),\n",
    "            activation,\n",
    "        )\n",
    "        if asymmetric:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(internal_channels, internal_channels, kernel_size=(kernel_size,1),\n",
    "                          stride=1, padding=(padding,0), dilation=dilation, bias=bias),\n",
    "                nn.BatchNorm2d(internal_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(internal_channels, internal_channels, kernel_size=(1,kernel_size),\n",
    "                          stride=1, padding=(0, padding), dilation=dilation, bias=bias),\n",
    "                nn.BatchNorm2d(internal_channels),\n",
    "                activation,\n",
    "            )\n",
    "        else:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(internal_channels, internal_channels, kernel_size=kernel_size,\n",
    "                          stride=1, padding=padding, dilation=dilation, bias=bias),\n",
    "                nn.BatchNorm2d(internal_channels),\n",
    "                activation,\n",
    "            )\n",
    "\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(internal_channels, channels, kernel_size=1, stride=1, bias=bias),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            activation,\n",
    "        )\n",
    "        self.ext_regu1 = nn.Dropout2d(p=dropout_prob)\n",
    "        self.out_prelu = activation\n",
    "\n",
    "    def forward(self, input):\n",
    "         main = input\n",
    "\n",
    "         ext = self.ext_conv1(input)\n",
    "         ext = self.ext_conv2(ext)\n",
    "         ext = self.ext_conv3(ext)\n",
    "         ext = self.ext_regu1(ext)\n",
    "\n",
    "         out = main + ext\n",
    "         return self.out_prelu(out)\n",
    "\n",
    "class DownsamplingBottleneck(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 kernel_size=3,\n",
    "                 padding=0,\n",
    "                 return_indices=False,\n",
    "                 dropout_prob=0.,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Store parameters that are needed later\n",
    "        self.return_indices = return_indices\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_max1 = nn.MaxPool2d(\n",
    "            kernel_size,\n",
    "            stride=2,\n",
    "            padding=padding,\n",
    "            return_indices=return_indices)\n",
    "\n",
    "        # Extension branch - 2x2 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 2x2 projection convolution with stride 2, no padding\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,internal_channels,kernel_size=2,stride=2,bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels),\n",
    "            activation\n",
    "        )\n",
    "\n",
    "        # Convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation)\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(out_channels), activation)\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_prelu = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        if self.return_indices:\n",
    "            main, max_indices = self.main_max1(x)\n",
    "        else:\n",
    "            main = self.main_max1(x)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Main branch channel padding\n",
    "        # calculate for padding ch_ext - ch_main\n",
    "        n, ch_ext, h, w = ext.size()\n",
    "        ch_main = main.size()[1]\n",
    "        padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
    "\n",
    "        # Before concatenating, check if main is on the CPU or GPU and\n",
    "        # convert padding accordingly\n",
    "        if main.is_cuda:\n",
    "            padding = padding.cuda()\n",
    "\n",
    "        # Concatenate, padding for less channels of main branch\n",
    "        main = torch.cat((main, padding), 1)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_prelu(out), max_indices\n",
    "\n",
    "class UpsamplingBottleneck(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 kernel_size=3,\n",
    "                 padding=0,\n",
    "                 dropout_prob=0.,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # Remember that the stride is the same as the kernel_size, just like\n",
    "        # the max pooling layers\n",
    "        self.main_unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 1x1 projection convolution with stride 1\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, internal_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels), activation)\n",
    "\n",
    "        # Transposed convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                internal_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=2,\n",
    "                padding=padding,\n",
    "                output_padding=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation)\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels), activation)\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_prelu = activation\n",
    "\n",
    "    def forward(self, x, max_indices):\n",
    "        # Main branch shortcut\n",
    "        main = self.main_conv1(x)\n",
    "        main = self.main_unpool1(main, max_indices)\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_prelu(out)\n",
    "\n",
    "class ENet(nn.Module):\n",
    "    def __init__(self, classes, encoder_relu=False, decoder_relu=True):\n",
    "        super().__init__()\n",
    "        # source code\n",
    "        self.name='BaseLine_ENet_trans'\n",
    "\n",
    "        self.initial_block = InitialBlock(3, 16, kernel_size=3 ,padding=1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        self.downsample1_0 = DownsamplingBottleneck(\n",
    "            16,\n",
    "            64,\n",
    "            padding=1,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.01,\n",
    "            relu=encoder_relu)\n",
    "        self.regular1_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_3 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_4 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        self.downsample2_0 = DownsamplingBottleneck(\n",
    "            64,\n",
    "            128,\n",
    "            padding=1,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.regular2_1 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_2 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_3 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_4 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular2_5 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_6 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_7 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_8 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        self.regular3_0 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_1 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_2 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_3 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular3_4 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_5 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_6 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_7 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        self.upsample4_0 = UpsamplingBottleneck(\n",
    "            128, 64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        self.upsample5_0 = UpsamplingBottleneck(\n",
    "            64, 16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular5_1 = RegularBottleneck(\n",
    "            16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.transposed_conv = nn.ConvTranspose2d(\n",
    "            16,\n",
    "            classes,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "            bias=False)\n",
    "\n",
    "        self.project_layer = nn.Conv2d(128, classes, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial block\n",
    "        x = self.initial_block(x)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        x, max_indices1_0 = self.downsample1_0(x)\n",
    "        x = self.regular1_1(x)\n",
    "        x = self.regular1_2(x)\n",
    "        x = self.regular1_3(x)\n",
    "        x = self.regular1_4(x)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        x, max_indices2_0 = self.downsample2_0(x)\n",
    "        x = self.regular2_1(x)\n",
    "        x = self.dilated2_2(x)\n",
    "        x = self.asymmetric2_3(x)\n",
    "        x = self.dilated2_4(x)\n",
    "        x = self.regular2_5(x)\n",
    "        x = self.dilated2_6(x)\n",
    "        x = self.asymmetric2_7(x)\n",
    "        x = self.dilated2_8(x)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        x = self.regular3_0(x)\n",
    "        x = self.dilated3_1(x)\n",
    "        x = self.asymmetric3_2(x)\n",
    "        x = self.dilated3_3(x)\n",
    "        x = self.regular3_4(x)\n",
    "        x = self.dilated3_5(x)\n",
    "        x = self.asymmetric3_6(x)\n",
    "        x = self.dilated3_7(x)\n",
    "\n",
    "        #x = self.project_layer(x)\n",
    "        #x = F.interpolate(x, scale_factor=8, mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        x = self.upsample4_0(x, max_indices2_0)\n",
    "        x = self.regular4_1(x)\n",
    "        x = self.regular4_2(x)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        x = self.upsample5_0(x, max_indices1_0)\n",
    "        x = self.regular5_1(x)\n",
    "        x = self.transposed_conv(x)\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# \"\"\"print layers and params of network\"\"\"\n",
    "# if __name__ == '__main__':\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model = ENet(classes=19).to(device)\n",
    "#     summary(model,(3,512,1024))\n",
    "#     # print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffc15c29e9045c99017fcfbcaea1244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03c20141beb4aaab18ca7573de0ccb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. inf >> 2.876 \n",
      "Epoch:1/30.. Train Loss: 3.038.. Val Loss: 2.876.. Train mIoU:0.022.. Val mIoU: 0.033.. Train Acc:0.123.. Val Acc:0.230.. Time: 8.12m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e737aff03ba6470db4f0882e8ced2691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6127a43835e44f36908cb2cf2a39633a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 2.876 >> 2.444 \n",
      "Epoch:2/30.. Train Loss: 2.687.. Val Loss: 2.444.. Train mIoU:0.039.. Val mIoU: 0.046.. Train Acc:0.311.. Val Acc:0.390.. Time: 32.76m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a35d4382b9e4255822efaa6a299f011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0288ba95ab54ed5b67cf5d3e2927c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 2.444 >> 2.060 \n",
      "Epoch:3/30.. Train Loss: 2.223.. Val Loss: 2.060.. Train mIoU:0.050.. Val mIoU: 0.056.. Train Acc:0.432.. Val Acc:0.468.. Time: 8.12m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eec51575cc742178cdb00509dba5076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e1b82203e14649b4664f6aaefb62d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 2.060 >> 1.812 \n",
      "saving model...\n",
      "Epoch:4/30.. Train Loss: 1.965.. Val Loss: 1.812.. Train mIoU:0.054.. Val mIoU: 0.058.. Train Acc:0.475.. Val Acc:0.514.. Time: 43.74m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42858613ef24cc8ad044174e5530122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c81975ac664cd79ac0d418bcda99ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.812 >> 1.626 \n",
      "Epoch:5/30.. Train Loss: 1.827.. Val Loss: 1.626.. Train mIoU:0.059.. Val mIoU: 0.066.. Train Acc:0.494.. Val Acc:0.537.. Time: 7.74m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd986e2cb0c749689d4eb8b6a2ad5911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1931b84ec4044007a76676147c1bcaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.626 >> 1.550 \n",
      "Epoch:6/30.. Train Loss: 1.751.. Val Loss: 1.550.. Train mIoU:0.066.. Val mIoU: 0.078.. Train Acc:0.505.. Val Acc:0.548.. Time: 7.67m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7544a79693434cbd632c762098b8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cefdac0c0e1490783e654a8b76cfa0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.550 >> 1.549 \n",
      "Epoch:7/30.. Train Loss: 1.746.. Val Loss: 1.549.. Train mIoU:0.069.. Val mIoU: 0.083.. Train Acc:0.495.. Val Acc:0.553.. Time: 7.71m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfae460d03e4d0ca7dbb7f92afe9a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ce7cb5b0654ae980c1d6330b7fbd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.549 >> 1.521 \n",
      "Epoch:8/30.. Train Loss: 1.687.. Val Loss: 1.521.. Train mIoU:0.074.. Val mIoU: 0.086.. Train Acc:0.515.. Val Acc:0.573.. Time: 24.41m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82651eae54c426baff27d61b92ec32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904d9b6da35048b6ab83020fc0f85763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.521 >> 1.507 \n",
      "saving model...\n",
      "Epoch:9/30.. Train Loss: 1.631.. Val Loss: 1.507.. Train mIoU:0.084.. Val mIoU: 0.097.. Train Acc:0.523.. Val Acc:0.566.. Time: 7.83m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c824f943d34879a3662f7ba5be31f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9b5e670ada437898adbf320b8e2248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.507 >> 1.419 \n",
      "Epoch:10/30.. Train Loss: 1.618.. Val Loss: 1.419.. Train mIoU:0.094.. Val mIoU: 0.099.. Train Acc:0.532.. Val Acc:0.572.. Time: 7.85m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfafe5d7b6245398cefc1e77da3043b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e428aada775642a4ad27d9b058953d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.419 >> 1.392 \n",
      "Epoch:11/30.. Train Loss: 1.601.. Val Loss: 1.392.. Train mIoU:0.096.. Val mIoU: 0.108.. Train Acc:0.538.. Val Acc:0.611.. Time: 7.84m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cf9dffa98c4e3e87f2c44f2a955402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe03ddd38aa4dc2a3f23ad231291978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Not Decrease for 1 time\n",
      "Epoch:12/30.. Train Loss: 1.537.. Val Loss: 1.462.. Train mIoU:0.103.. Val mIoU: 0.106.. Train Acc:0.555.. Val Acc:0.569.. Time: 7.85m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c171ddc0464163828bbd3f56c09445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673ffa75e10f46408602c8146a82483f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Not Decrease for 2 time\n",
      "Epoch:13/30.. Train Loss: 1.531.. Val Loss: 1.498.. Train mIoU:0.107.. Val mIoU: 0.099.. Train Acc:0.564.. Val Acc:0.572.. Time: 7.84m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c40dedae4a4dd2872aefdfa71fc7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec8c4034f52491c9aa9717c93ccd15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.498 >> 1.351 \n",
      "Epoch:14/30.. Train Loss: 1.509.. Val Loss: 1.351.. Train mIoU:0.108.. Val mIoU: 0.117.. Train Acc:0.563.. Val Acc:0.607.. Time: 7.85m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa95e60f09340bcbac29cc5b526c54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765adcc776cc4601993fb4d2b96156aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Not Decrease for 3 time\n",
      "Epoch:15/30.. Train Loss: 1.479.. Val Loss: 1.489.. Train mIoU:0.115.. Val mIoU: 0.111.. Train Acc:0.579.. Val Acc:0.570.. Time: 7.86m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d6f0885b38486ebb3a0ec2961e4705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7d38cd878842439f0e3340589ce401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.489 >> 1.264 \n",
      "Epoch:16/30.. Train Loss: 1.359.. Val Loss: 1.264.. Train mIoU:0.127.. Val mIoU: 0.140.. Train Acc:0.609.. Val Acc:0.660.. Time: 7.91m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b85fe28855042bd97a8aa25be462071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa2c6d7b6dd4120b915f1b89f6f482b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Not Decrease for 4 time\n",
      "Epoch:17/30.. Train Loss: 1.387.. Val Loss: 1.303.. Train mIoU:0.127.. Val mIoU: 0.133.. Train Acc:0.606.. Val Acc:0.630.. Time: 7.85m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85208dc486cb48adb9d66e678a71b6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760caf4df0ec4f198072650fabd7eb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Not Decrease for 5 time\n",
      "Epoch:18/30.. Train Loss: 1.378.. Val Loss: 1.318.. Train mIoU:0.129.. Val mIoU: 0.132.. Train Acc:0.607.. Val Acc:0.638.. Time: 7.86m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4da0ed3ccc497685d42890546122e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6b1c373899498f8ee3b03eea3bf79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.318 >> 1.208 \n",
      "saving model...\n",
      "Epoch:19/30.. Train Loss: 1.348.. Val Loss: 1.208.. Train mIoU:0.134.. Val mIoU: 0.147.. Train Acc:0.620.. Val Acc:0.677.. Time: 7.86m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ddc36da1c74bd39fb73a5e09f70c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29e71187a5f49fa8ccf8593658a11c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.208 >> 1.205 \n",
      "Epoch:20/30.. Train Loss: 1.344.. Val Loss: 1.205.. Train mIoU:0.132.. Val mIoU: 0.148.. Train Acc:0.616.. Val Acc:0.676.. Time: 7.86m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49518b35b394236b84e1ba5ace95513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec6c73ed5ac41c2aa3faccd04864b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Not Decrease for 6 time\n",
      "Epoch:21/30.. Train Loss: 1.295.. Val Loss: 1.263.. Train mIoU:0.139.. Val mIoU: 0.142.. Train Acc:0.633.. Val Acc:0.669.. Time: 7.78m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5950713305894774b6e054340f5b0fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88abeaf648fb4bbe9f233b86c00cc90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.263 >> 1.225 \n",
      "Epoch:22/30.. Train Loss: 1.257.. Val Loss: 1.225.. Train mIoU:0.141.. Val mIoU: 0.153.. Train Acc:0.641.. Val Acc:0.661.. Time: 7.76m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc74c3eb8c8452f9b83de2a066a08be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689b4253bb354bcb8f3451002399e454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.225 >> 1.204 \n",
      "Epoch:23/30.. Train Loss: 1.292.. Val Loss: 1.204.. Train mIoU:0.138.. Val mIoU: 0.146.. Train Acc:0.628.. Val Acc:0.664.. Time: 7.77m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d508c755381e437486a63f49d53415d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9338de9ff940f7892b4e4b1f6d74fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.204 >> 1.181 \n",
      "Epoch:24/30.. Train Loss: 1.244.. Val Loss: 1.181.. Train mIoU:0.146.. Val mIoU: 0.151.. Train Acc:0.649.. Val Acc:0.677.. Time: 16.94m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637f02c2e34540b28ae7b865b81122cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f40fc6bfb6341b794f529bbda0340c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.181 >> 1.173 \n",
      "saving model...\n",
      "Epoch:25/30.. Train Loss: 1.220.. Val Loss: 1.173.. Train mIoU:0.148.. Val mIoU: 0.155.. Train Acc:0.653.. Val Acc:0.679.. Time: 7.86m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f909639571444afdbab4db699e13865a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80fa86f4ff944288a9744e25d90a050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Decreasing.. 1.173 >> 1.131 \n",
      "Epoch:26/30.. Train Loss: 1.192.. Val Loss: 1.131.. Train mIoU:0.151.. Val mIoU: 0.162.. Train Acc:0.662.. Val Acc:0.693.. Time: 7.85m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0514ab98104f9f883db0903bc7fbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f81a371d0d4e199e8239eacc7047ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Not Decrease for 7 time\n",
      "Loss not decrease for 7 times, Stop Training\n",
      "Total time: 298.29 m\n"
     ]
    }
   ],
   "source": [
    "max_lr = 1e-3\n",
    "epoch = 30\n",
    "weight_decay = 1e-4\n",
    "e_net  = ENet(classes=23)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(e_net.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n",
    "                                            steps_per_epoch=len(train_loader))\n",
    "\n",
    "history = fit(epoch, e_net, train_loader, val_loader, criterion, optimizer, sched)#, model_type='ENet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "#SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\n",
    "#Paper-Link: https://arxiv.org/pdf/1511.00561.pdf\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "\n",
    "__all__ = [\"SegNet\"]\n",
    "\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self,classes= 19):\n",
    "        super(SegNet, self).__init__()\n",
    "\n",
    "        batchNorm_momentum = 0.1\n",
    "\n",
    "        self.conv11 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn11 = nn.BatchNorm2d(64, momentum= batchNorm_momentum)\n",
    "        self.conv12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn12 = nn.BatchNorm2d(64, momentum= batchNorm_momentum)\n",
    "\n",
    "        self.conv21 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn21 = nn.BatchNorm2d(128, momentum= batchNorm_momentum)\n",
    "        self.conv22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn22 = nn.BatchNorm2d(128, momentum= batchNorm_momentum)\n",
    "\n",
    "        self.conv31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn31 = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
    "        self.conv32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn32 = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
    "        self.conv33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn33 = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
    "\n",
    "        self.conv41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn41 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "        self.conv42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn42 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "        self.conv43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn43 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "\n",
    "        self.conv51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn51 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "        self.conv52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn52 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "        self.conv53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn53 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "\n",
    "        self.conv53d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn53d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "        self.conv52d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn52d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "        self.conv51d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn51d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "\n",
    "        self.conv43d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn43d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "        self.conv42d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn42d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
    "        self.conv41d = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.bn41d = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
    "\n",
    "        self.conv33d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn33d = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
    "        self.conv32d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn32d = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
    "        self.conv31d = nn.Conv2d(256,  128, kernel_size=3, padding=1)\n",
    "        self.bn31d = nn.BatchNorm2d(128, momentum= batchNorm_momentum)\n",
    "\n",
    "        self.conv22d = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn22d = nn.BatchNorm2d(128, momentum= batchNorm_momentum)\n",
    "        self.conv21d = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.bn21d = nn.BatchNorm2d(64, momentum= batchNorm_momentum)\n",
    "\n",
    "        self.conv12d = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn12d = nn.BatchNorm2d(64, momentum= batchNorm_momentum)\n",
    "        self.conv11d = nn.Conv2d(64, classes, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Stage 1\n",
    "        x11 = F.relu(self.bn11(self.conv11(x)))\n",
    "        x12 = F.relu(self.bn12(self.conv12(x11)))\n",
    "        x1_size = x12.size()\n",
    "        x1p, id1 = F.max_pool2d(x12,kernel_size=2, stride=2,return_indices=True)\n",
    "\n",
    "        # Stage 2\n",
    "        x21 = F.relu(self.bn21(self.conv21(x1p)))\n",
    "        x22 = F.relu(self.bn22(self.conv22(x21)))\n",
    "        x2_size = x22.size()\n",
    "        x2p, id2 = F.max_pool2d(x22,kernel_size=2, stride=2,return_indices=True)\n",
    "\n",
    "        # Stage 3\n",
    "        x31 = F.relu(self.bn31(self.conv31(x2p)))\n",
    "        x32 = F.relu(self.bn32(self.conv32(x31)))\n",
    "        x33 = F.relu(self.bn33(self.conv33(x32)))\n",
    "        x3_size = x33.size()\n",
    "        x3p, id3 = F.max_pool2d(x33,kernel_size=2, stride=2,return_indices=True)\n",
    "\n",
    "        # Stage 4\n",
    "        x41 = F.relu(self.bn41(self.conv41(x3p)))\n",
    "        x42 = F.relu(self.bn42(self.conv42(x41)))\n",
    "        x43 = F.relu(self.bn43(self.conv43(x42)))\n",
    "        x4_size = x43.size()\n",
    "        x4p, id4 = F.max_pool2d(x43,kernel_size=2, stride=2,return_indices=True)\n",
    "\n",
    "        # Stage 5\n",
    "        x51 = F.relu(self.bn51(self.conv51(x4p)))\n",
    "        x52 = F.relu(self.bn52(self.conv52(x51)))\n",
    "        x53 = F.relu(self.bn53(self.conv53(x52)))\n",
    "        x5_size = x53.size()\n",
    "        x5p, id5 = F.max_pool2d(x53,kernel_size=2, stride=2,return_indices=True)\n",
    "\n",
    "\n",
    "        # Stage 5d\n",
    "        x5d = F.max_unpool2d(x5p, id5, kernel_size=2, stride=2, output_size=x5_size)\n",
    "        x53d = F.relu(self.bn53d(self.conv53d(x5d)))\n",
    "        x52d = F.relu(self.bn52d(self.conv52d(x53d)))\n",
    "        x51d = F.relu(self.bn51d(self.conv51d(x52d)))\n",
    "\n",
    "        # Stage 4d\n",
    "        x4d = F.max_unpool2d(x51d, id4, kernel_size=2, stride=2, output_size=x4_size)\n",
    "        x43d = F.relu(self.bn43d(self.conv43d(x4d)))\n",
    "        x42d = F.relu(self.bn42d(self.conv42d(x43d)))\n",
    "        x41d = F.relu(self.bn41d(self.conv41d(x42d)))\n",
    "\n",
    "        # Stage 3d\n",
    "        x3d = F.max_unpool2d(x41d, id3, kernel_size=2, stride=2, output_size=x3_size)\n",
    "        x33d = F.relu(self.bn33d(self.conv33d(x3d)))\n",
    "        x32d = F.relu(self.bn32d(self.conv32d(x33d)))\n",
    "        x31d = F.relu(self.bn31d(self.conv31d(x32d)))\n",
    "\n",
    "        # Stage 2d\n",
    "        x2d = F.max_unpool2d(x31d, id2, kernel_size=2, stride=2, output_size=x2_size)\n",
    "        x22d = F.relu(self.bn22d(self.conv22d(x2d)))\n",
    "        x21d = F.relu(self.bn21d(self.conv21d(x22d)))\n",
    "\n",
    "        # Stage 1d\n",
    "        x1d = F.max_unpool2d(x21d, id1, kernel_size=2, stride=2, output_size=x1_size)\n",
    "        x12d = F.relu(self.bn12d(self.conv12d(x1d)))\n",
    "        x11d = self.conv11d(x12d)\n",
    "\n",
    "        return x11d\n",
    "\n",
    "    def load_from_segnet(self, model_path):\n",
    "        s_dict = self.state_dict()# create a copy of the state dict\n",
    "        th = torch.load(model_path).state_dict() # load the weigths\n",
    "        # for name in th:\n",
    "            # s_dict[corresp_name[name]] = th[name]\n",
    "        self.load_state_dict(th)\n",
    "\n",
    "\n",
    "\n",
    "# \"\"\"print layers and params of network\"\"\"\n",
    "# if __name__ == '__main__':\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model = SegNet(classes=19).to(device)\n",
    "#     summary(model,(3,512,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "#ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation\n",
    "#Paper-Link:  https://arxiv.org/pdf/1606.02147.pdf\n",
    "##################################################################################\n",
    "\n",
    "# @misc{Efficient-Segmentation-Networks,\n",
    "#   author = {Yu Wang},\n",
    "#   title = {Efficient-Segmentation-Networks Pytorch Implementation},\n",
    "#   year = {2019},\n",
    "#   publisher = {GitHub},\n",
    "#   journal = {GitHub repository},\n",
    "#   howpublished = {\\url{https://github.com/xiaoyufenfei/Efficient-Segmentation-Networks}},\n",
    "#   commit = {master}\n",
    "# }\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "__all__ = [\"ENet\"]\n",
    "\n",
    "\n",
    "class InitialBlock(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels, kernel_size, padding=0, bias=False,relu=True):\n",
    "        super(InitialBlock, self).__init__()\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "\n",
    "        self.main_branch = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels-3,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=2,\n",
    "            padding=padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "        # MP need padding too\n",
    "        self.ext_branch = nn.MaxPool2d(kernel_size, stride=2, padding=padding)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.out_prelu = activation\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        main = self.main_branch(input)\n",
    "        ext = self.ext_branch(input)\n",
    "\n",
    "        out = torch.cat((main, ext), dim=1)\n",
    "\n",
    "        out = self.batch_norm(out)\n",
    "        return self.out_prelu(out)\n",
    "\n",
    "class RegularBottleneck(nn.Module):\n",
    "    def __init__(self, channels, internal_ratio=4, kernel_size=3, padding=0,\n",
    "                 dilation=1, asymmetric=False, dropout_prob=0., bias=False, relu=True):\n",
    "        super(RegularBottleneck, self).__init__()\n",
    "\n",
    "        internal_channels = channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "\n",
    "        # 1x1 projection conv\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(channels, internal_channels, kernel_size=1, stride=1, bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels),\n",
    "            activation,\n",
    "        )\n",
    "        if asymmetric:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(internal_channels, internal_channels, kernel_size=(kernel_size,1),\n",
    "                          stride=1, padding=(padding,0), dilation=dilation, bias=bias),\n",
    "                nn.BatchNorm2d(internal_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(internal_channels, internal_channels, kernel_size=(1,kernel_size),\n",
    "                          stride=1, padding=(0, padding), dilation=dilation, bias=bias),\n",
    "                nn.BatchNorm2d(internal_channels),\n",
    "                activation,\n",
    "            )\n",
    "        else:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(internal_channels, internal_channels, kernel_size=kernel_size,\n",
    "                          stride=1, padding=padding, dilation=dilation, bias=bias),\n",
    "                nn.BatchNorm2d(internal_channels),\n",
    "                activation,\n",
    "            )\n",
    "\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(internal_channels, channels, kernel_size=1, stride=1, bias=bias),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            activation,\n",
    "        )\n",
    "        self.ext_regu1 = nn.Dropout2d(p=dropout_prob)\n",
    "        self.out_prelu = activation\n",
    "\n",
    "    def forward(self, input):\n",
    "         main = input\n",
    "\n",
    "         ext = self.ext_conv1(input)\n",
    "         ext = self.ext_conv2(ext)\n",
    "         ext = self.ext_conv3(ext)\n",
    "         ext = self.ext_regu1(ext)\n",
    "\n",
    "         out = main + ext\n",
    "         return self.out_prelu(out)\n",
    "\n",
    "class DownsamplingBottleneck(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 kernel_size=3,\n",
    "                 padding=0,\n",
    "                 return_indices=False,\n",
    "                 dropout_prob=0.,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Store parameters that are needed later\n",
    "        self.return_indices = return_indices\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_max1 = nn.MaxPool2d(\n",
    "            kernel_size,\n",
    "            stride=2,\n",
    "            padding=padding,\n",
    "            return_indices=return_indices)\n",
    "\n",
    "        # Extension branch - 2x2 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 2x2 projection convolution with stride 2, no padding\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,internal_channels,kernel_size=2,stride=2,bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels),\n",
    "            activation\n",
    "        )\n",
    "\n",
    "        # Convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation)\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(out_channels), activation)\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_prelu = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        if self.return_indices:\n",
    "            main, max_indices = self.main_max1(x)\n",
    "        else:\n",
    "            main = self.main_max1(x)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Main branch channel padding\n",
    "        # calculate for padding ch_ext - ch_main\n",
    "        n, ch_ext, h, w = ext.size()\n",
    "        ch_main = main.size()[1]\n",
    "        padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
    "\n",
    "        # Before concatenating, check if main is on the CPU or GPU and\n",
    "        # convert padding accordingly\n",
    "        if main.is_cuda:\n",
    "            padding = padding.cuda()\n",
    "\n",
    "        # Concatenate, padding for less channels of main branch\n",
    "        main = torch.cat((main, padding), 1)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_prelu(out), max_indices\n",
    "\n",
    "class UpsamplingBottleneck(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 kernel_size=3,\n",
    "                 padding=0,\n",
    "                 dropout_prob=0.,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # Remember that the stride is the same as the kernel_size, just like\n",
    "        # the max pooling layers\n",
    "        self.main_unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 1x1 projection convolution with stride 1\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, internal_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels), activation)\n",
    "\n",
    "        # Transposed convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                internal_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=2,\n",
    "                padding=padding,\n",
    "                output_padding=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation)\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels), activation)\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_prelu = activation\n",
    "\n",
    "    def forward(self, x, max_indices):\n",
    "        # Main branch shortcut\n",
    "        main = self.main_conv1(x)\n",
    "        main = self.main_unpool1(main, max_indices)\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_prelu(out)\n",
    "\n",
    "class ENet(nn.Module):\n",
    "    def __init__(self, classes, encoder_relu=False, decoder_relu=True):\n",
    "        super().__init__()\n",
    "        # source code\n",
    "        self.name='BaseLine_ENet_trans'\n",
    "\n",
    "        self.initial_block = InitialBlock(3, 16, kernel_size=3 ,padding=1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        self.downsample1_0 = DownsamplingBottleneck(\n",
    "            16,\n",
    "            64,\n",
    "            padding=1,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.01,\n",
    "            relu=encoder_relu)\n",
    "        self.regular1_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_3 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_4 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        self.downsample2_0 = DownsamplingBottleneck(\n",
    "            64,\n",
    "            128,\n",
    "            padding=1,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.regular2_1 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_2 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_3 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_4 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular2_5 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_6 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_7 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_8 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        self.regular3_0 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_1 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_2 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_3 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular3_4 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_5 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_6 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_7 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        self.upsample4_0 = UpsamplingBottleneck(\n",
    "            128, 64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        self.upsample5_0 = UpsamplingBottleneck(\n",
    "            64, 16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular5_1 = RegularBottleneck(\n",
    "            16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.transposed_conv = nn.ConvTranspose2d(\n",
    "            16,\n",
    "            classes,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "            bias=False)\n",
    "\n",
    "        self.project_layer = nn.Conv2d(128, classes, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial block\n",
    "        x = self.initial_block(x)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        x, max_indices1_0 = self.downsample1_0(x)\n",
    "        x = self.regular1_1(x)\n",
    "        x = self.regular1_2(x)\n",
    "        x = self.regular1_3(x)\n",
    "        x = self.regular1_4(x)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        x, max_indices2_0 = self.downsample2_0(x)\n",
    "        x = self.regular2_1(x)\n",
    "        x = self.dilated2_2(x)\n",
    "        x = self.asymmetric2_3(x)\n",
    "        x = self.dilated2_4(x)\n",
    "        x = self.regular2_5(x)\n",
    "        x = self.dilated2_6(x)\n",
    "        x = self.asymmetric2_7(x)\n",
    "        x = self.dilated2_8(x)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        x = self.regular3_0(x)\n",
    "        x = self.dilated3_1(x)\n",
    "        x = self.asymmetric3_2(x)\n",
    "        x = self.dilated3_3(x)\n",
    "        x = self.regular3_4(x)\n",
    "        x = self.dilated3_5(x)\n",
    "        x = self.asymmetric3_6(x)\n",
    "        x = self.dilated3_7(x)\n",
    "\n",
    "        #x = self.project_layer(x)\n",
    "        #x = F.interpolate(x, scale_factor=8, mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        x = self.upsample4_0(x, max_indices2_0)\n",
    "        x = self.regular4_1(x)\n",
    "        x = self.regular4_2(x)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        x = self.upsample5_0(x, max_indices1_0)\n",
    "        x = self.regular5_1(x)\n",
    "        x = self.transposed_conv(x)\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# \"\"\"print layers and params of network\"\"\"\n",
    "# if __name__ == '__main__':\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model = ENet(classes=19).to(device)\n",
    "#     summary(model,(3,512,1024))\n",
    "#     # print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c81fc1c08ca469fa03da95f4b1f5d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'SegNet' object has no attribute 'bn11'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mmax_lr, weight_decay\u001b[39m=\u001b[39mweight_decay)\n\u001b[1;32m      7\u001b[0m sched \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mOneCycleLR(optimizer, max_lr, epochs\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m      8\u001b[0m                                             steps_per_epoch\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_loader))\n\u001b[0;32m---> 10\u001b[0m history \u001b[39m=\u001b[39m fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)\n",
      "Cell \u001b[0;32mIn[15], line 36\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch)\u001b[0m\n\u001b[1;32m     34\u001b[0m image \u001b[39m=\u001b[39m image_tiles\u001b[39m.\u001b[39mto(device); mask \u001b[39m=\u001b[39m mask_tiles\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     35\u001b[0m \u001b[39m#forward\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m output \u001b[39m=\u001b[39m model(image)\n\u001b[1;32m     37\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, mask)\n\u001b[1;32m     38\u001b[0m \u001b[39m#evaluation metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[18], line 88\u001b[0m, in \u001b[0;36mSegNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m     \u001b[39m# Stage 1\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     x11 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn11(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv11(x)))\n\u001b[1;32m     89\u001b[0m     x12 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn12(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv12(x11)))\n\u001b[1;32m     90\u001b[0m     x1p, idx1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x12)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SegNet' object has no attribute 'bn11'"
     ]
    }
   ],
   "source": [
    "max_lr = 1e-3\n",
    "epoch = 30\n",
    "weight_decay = 1e-4\n",
    "model  = SegNet(classes=23).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n",
    "                                            steps_per_epoch=len(train_loader))\n",
    "\n",
    "history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Costum model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64)) \n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = UNet(n_channels=3, n_classes=1, bilinear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225b2dd6072546b28450c27dead671ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "max_lr = 1e-3\n",
    "epoch = 30\n",
    "weight_decay = 1e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model_new.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n",
    "                                            steps_per_epoch=len(train_loader))\n",
    "\n",
    "history = fit(epoch, model_new, train_loader, val_loader, criterion, optimizer, sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
